{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPj7nUjU3x/UadBV7mJtzt+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c09709d75d6c4e5eaba2fb744ce22871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcc87d7090ed412c8561873a24df9a3a",
              "IPY_MODEL_0d300c7016cc433ca6fdf4a931d84fc4",
              "IPY_MODEL_27be9de2777c4577a3b754e6942ad087"
            ],
            "layout": "IPY_MODEL_e605baf3dc7f46c3a9903128d0a84074"
          }
        },
        "fcc87d7090ed412c8561873a24df9a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd339be5318d4d28b2edd344ef56ef3c",
            "placeholder": "​",
            "style": "IPY_MODEL_858add2fd6de447ca9cff6857819e041",
            "value": "Map: 100%"
          }
        },
        "0d300c7016cc433ca6fdf4a931d84fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8812a2c0765947c899dac57bed6412f6",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8d1680e33de49b192c2dbe61f99859d",
            "value": 25000
          }
        },
        "27be9de2777c4577a3b754e6942ad087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b6da26d7184ecfa295d5196c53fb53",
            "placeholder": "​",
            "style": "IPY_MODEL_08e6d9dd37da4884b0e236c436dcc376",
            "value": " 25000/25000 [00:58&lt;00:00, 391.54 examples/s]"
          }
        },
        "e605baf3dc7f46c3a9903128d0a84074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd339be5318d4d28b2edd344ef56ef3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "858add2fd6de447ca9cff6857819e041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8812a2c0765947c899dac57bed6412f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d1680e33de49b192c2dbe61f99859d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56b6da26d7184ecfa295d5196c53fb53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e6d9dd37da4884b0e236c436dcc376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Опционально: указать конкретную GPU (например, \"0\" или \"0,1\" для нескольких)\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Проверяем доступность GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используем устройство: {device}\")\n",
        "\n",
        "# Загружаем датасет\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Инициализируем токенизатор и модель\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.to(device)  # Перемещаем модель на GPU\n",
        "\n",
        "# Токенизация\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Выбираем подмножества для ускоренного обучения\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "# Настройка параметров обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    seed=42,\n",
        ")\n",
        "training_args.evaluation_strategy = \"epoch\"\n",
        "# Создаем Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "trainer.train()\n",
        "\n",
        "# Оценка\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "c09709d75d6c4e5eaba2fb744ce22871",
            "fcc87d7090ed412c8561873a24df9a3a",
            "0d300c7016cc433ca6fdf4a931d84fc4",
            "27be9de2777c4577a3b754e6942ad087",
            "e605baf3dc7f46c3a9903128d0a84074",
            "fd339be5318d4d28b2edd344ef56ef3c",
            "858add2fd6de447ca9cff6857819e041",
            "8812a2c0765947c899dac57bed6412f6",
            "a8d1680e33de49b192c2dbe61f99859d",
            "56b6da26d7184ecfa295d5196c53fb53",
            "08e6d9dd37da4884b0e236c436dcc376"
          ]
        },
        "id": "MpfS_jwqa9mz",
        "outputId": "b25fa4c0-2436-4b80-c748-c75fbc7dddc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используем устройство: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c09709d75d6c4e5eaba2fb744ce22871"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-35b720ec6eca>:44: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m8tem\u001b[0m (\u001b[33m8tem-mirea\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250529_003528-iacots99</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/8tem-mirea/huggingface/runs/iacots99' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/8tem-mirea/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/8tem-mirea/huggingface' target=\"_blank\">https://wandb.ai/8tem-mirea/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/8tem-mirea/huggingface/runs/iacots99' target=\"_blank\">https://wandb.ai/8tem-mirea/huggingface/runs/iacots99</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:32, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.691400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.364200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3219926953315735,\n",
              " 'eval_runtime': 27.784,\n",
              " 'eval_samples_per_second': 35.992,\n",
              " 'eval_steps_per_second': 4.499,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model=512, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        Q = self.W_q(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "        K = self.W_k(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "        V = self.W_v(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        attention = torch.softmax(scores, dim=-1)\n",
        "        output = torch.matmul(attention, V)\n",
        "\n",
        "        output = output.transpose(1,2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.W_o(output)"
      ],
      "metadata": {
        "id": "SqXM8RRdg-1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, ff_dim=2048):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, d_model)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output = self.attention(x)\n",
        "        x = self.norm1(x + attn_output)\n",
        "        ff_output = self.ff(x)\n",
        "        return self.norm2(x + ff_output)"
      ],
      "metadata": {
        "id": "ANbeqvwZhKoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_sentiment(texts, model, tokenizer, device):\n",
        "    model.eval()\n",
        "    # Токенизация\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    # Перемещаем входные данные на устройство модели (GPU или CPU)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        preds = torch.argmax(probs, dim=-1)\n",
        "\n",
        "    return preds.cpu().numpy(), probs.cpu().numpy()\n",
        "\n",
        "# Пример использования\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используем устройство: {device}\")\n",
        "\n",
        "# Предполагается, что model и tokenizer уже загружены\n",
        "model.to(device)\n",
        "\n",
        "texts = [\n",
        "    \"This movie was fantastic! I really enjoyed it.\",\n",
        "    \"Terrible film. Waste of time.\",\n",
        "    \"It was okay, not the best but not the worst.\"\n",
        "]\n",
        "\n",
        "preds, probs = predict_sentiment(texts, model, tokenizer, device)\n",
        "\n",
        "for text, pred, prob in zip(texts, preds, probs):\n",
        "    label = \"Positive\" if pred == 1 else \"Negative\"\n",
        "    confidence = prob[pred]\n",
        "    print(f\"Text: {text}\\nPrediction: {label} (confidence: {confidence:.2f})\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0_U6yfshXod",
        "outputId": "5bf29fb9-4e70-48ce-cd77-0cc47d38b331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используем устройство: cuda\n",
            "Text: This movie was fantastic! I really enjoyed it.\n",
            "Prediction: Positive (confidence: 0.97)\n",
            "\n",
            "Text: Terrible film. Waste of time.\n",
            "Prediction: Negative (confidence: 0.96)\n",
            "\n",
            "Text: It was okay, not the best but not the worst.\n",
            "Prediction: Negative (confidence: 0.87)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем первые 10 примеров\n",
        "test_samples = small_eval_dataset.select(range(10))\n",
        "\n",
        "# Извлекаем тексты из токенизированных input_ids\n",
        "texts = [tokenizer.decode(x['input_ids'], skip_special_tokens=True) for x in test_samples]\n",
        "\n",
        "# Извлекаем метки\n",
        "labels = [x['label'] for x in test_samples]\n",
        "\n",
        "# Определяем устройство (GPU, если доступен)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)  # Перемещаем модель на устройство\n",
        "\n",
        "# Предсказания модели с передачей устройства\n",
        "preds, probs = predict_sentiment(texts, model, tokenizer, device)\n",
        "\n",
        "# Вывод результатов\n",
        "for text, true_label, pred, prob in zip(texts, labels, preds, probs):\n",
        "    true_str = \"Positive\" if true_label == 1 else \"Negative\"\n",
        "    pred_str = \"Positive\" if pred == 1 else \"Negative\"\n",
        "    confidence = prob[pred]\n",
        "    print(f\"Text: {text}\\nTrue: {true_str}, Predicted: {pred_str} (confidence: {confidence:.2f})\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4evPHDiihlkh",
        "outputId": "5e557c31-a499-49ec-f606-cffc717a14ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: < br / > < br / > when i unsuspectedly rented a thousand acres, i thought i was in for an entertaining king lear story and of course michelle pfeiffer was in it, so what could go wrong? < br / > < br / > very quickly, however, i realized that this story was about a thousand other things besides just acres. i started crying and couldn ' t stop until long after the movie ended. thank you jane, laura and jocelyn, for bringing us such a wonderfully subtle and compassionate movie! thank you cast, for being involved and portraying the characters with such depth and gentleness! < br / > < br / > i recognized the angry sister ; the runaway sister and the sister in denial. i recognized the abusive husband and why he was there and then the father, oh oh the father... all superbly played. i also recognized myself and this movie was an eye - opener, a relief, a chance to face my own truth and finally doing something about it. i truly hope a thousand acres has had the same effect on some others out there. < br / > < br / > since i didn ' t understand why the cover said the film was about sisters fighting over land - they weren ' t fighting each other at all - i watched it a second time. then i was able to see that if one hadn ' t lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. that is exactly the reason why people in general often overlook the truth about their neighbors for instance. < br / > < br / > but yet another reason why this movie is so perfect! < br / > < br / > i don ' t give a rat ' s ass ( pardon my french ) about to what extend the king lear story is followed. all i know is that i can honestly say : this movie has changed my life. < br / > < br / > keep up the good work guys, you can and do make a difference. < br / > < br / >\n",
            "True: Positive, Predicted: Positive (confidence: 0.97)\n",
            "\n",
            "Text: this is the latest entry in the long series of films with the french agent, o. s. s. 117 ( the french answer to james bond ). the series was launched in the early 1950 ' s, and spawned at least eight films ( none of which was ever released in the u. s. ). ' o. s. s. 117 : cairo, nest of spies ' is a breezy little comedy that should not... repeat not, be taken too seriously. our protagonist finds himself in the middle of a spy chase in egypt ( with morroco doing stand in for egypt ) to find out about a long lost friend. what follows is the standard james bond / inspector cloussou kind of antics. although our man is something of an overt xenophobe, sexist, homophobe, it ' s treated as pure farce ( as i said, don ' t take it too seriously ). although there is a bit of rough language & cartoon violence, it ' s basically okay for older kids ( ages 12 & up ). as previously stated in the subject line, just sit back, pass the popcorn & just enjoy.\n",
            "True: Positive, Predicted: Positive (confidence: 0.90)\n",
            "\n",
            "Text: this movie was so frustrating. everything seemed energetic and i was totally prepared to have a good time. i at least thought i ' d be able to stand it. but, i was wrong. first, the weird looping? it was like watching \" america ' s funniest home videos \". the damn parents. i hated them so much. the stereo - typical latino family? i need to speak with the person responsible for this. we need to have a talk. that little girl who was always hanging on someone? i just hated her and had to mention it. now, the final scene transcends, i must say. it ' s so gloriously bad and full of badness that it is a movie of its own. what crappy dancing. horrible and beautiful at once.\n",
            "True: Negative, Predicted: Negative (confidence: 0.97)\n",
            "\n",
            "Text: i was truly and wonderfully surprised at \" o ' brother, where art thou? \" the video store was out of all the movies i was planning on renting, so then i came across this. i came home and as i watched i became engrossed and found myself laughing out loud. the coen ' s have made a magnificiant film again. but i think the first time you watch this movie, you get to know the characters. the second time, now that you know them, you laugh sooo hard it could hurt you. i strongly would reccomend anyone seeing this because if you are not, you are truly missing a film gem for the ages. 10 / 10\n",
            "True: Positive, Predicted: Positive (confidence: 0.95)\n",
            "\n",
            "Text: this movie spends most of its time preaching that it is the script that makes the movie, but apparently there was no script when they shot this waste of time! the trailer makes this out to be a comedy, but the film can ' t decide if it wants to be a comedy, a drama, a romance or an action film. press releases indicated that shatner and hamlin made this movie because they loved the script ( what were they thinking? ). if you like william shatner ( i do ) see \" free enterprise \" instead.\n",
            "True: Negative, Predicted: Negative (confidence: 0.96)\n",
            "\n",
            "Text: after a very long time marathi cinema has come with some good movie. this movie is one of the best marathi movies ever made. it shows how a old grandfather tries to save his grandsons eye. he tries everything that is possible in his hands to save the child ' s eye. doctor and a relative of his tries to help him in his attempt. < br / > < br / > the acting by the grandfather, the boy and the doctor are simply superb. they have shown true picture of a typical marathi life. every bit of action has some meaning in it. i would recommend to watch this movie, as initially i thought this one would be of documentary type but this was above my expectations. < br / > < br / > this film is really going to touch your hearts. i would expect more marathi movies to come up with performances like this.\n",
            "True: Positive, Predicted: Positive (confidence: 0.98)\n",
            "\n",
            "Text: this is a really sad, and touching movie! it deals with the subject of child abuse. it ' s really sad, but mostly a true story, because it happens everyday. elijah wood and joseph mazzello play the two children or lorraine bracco, a single mother who just tries to make a home for them. while living with her parents, a man, who likes to be called \" the king \" comes into their life. he hits the youngest boy, bobby, but the two brothers vow not to tell their mother. but finally she finds out, after the bobby is hurt badly. the end kind of ruined it for me, because it is so totally unbelievable. but, except for that, i love the movie.\n",
            "True: Positive, Predicted: Positive (confidence: 0.97)\n",
            "\n",
            "Text: don ' t pay any attention to the rave reviews of this film here. it is the worst van damme film and one of the worst of any sort i have ever seen. it would appeal to somebody with no depth whatever who requires nothing more than gunfire and explosions to be entertained. < br / > < br / > seeing that this is directed by peter hyams it has made me realise that peter has no talent as a director, but is very good at filming explosions and the like. however, movies need other elements as well ; for example, a story. this one didn ' t have one. this might explain the awfulness of some of mr. hyams ' more recent films, hardly any better than this one, really. < br / > < br / > one can ' t help wondering how some people ever were put behind a camera.\n",
            "True: Negative, Predicted: Negative (confidence: 0.98)\n",
            "\n",
            "Text: porn legend gregory dark directs this cheesy horror flick that has glen jacobs ( kane from wwf / wwe / whatever it calls itself nowadays ) in his cinematic debut. he plays jacob goodknight, a blind serial killer who ' s forte is taking people ' s eyes out. the plot, be it as it may, has a group of troubled youths cleaning up the historical hotel that goodknight resides in and subsequently being offed by him. hemmingway it ' s not. starts of as fun dopey b - movie, but soon gets too tedious to be enjoyable. glad i went in with pretty low expectations, but even those weren ' t met. how can you have a porn king directing and still suffer from a lack of nudity??? for shame. < br / > < br / > my grade : d - < br / > < br / > eye candy : samantha noble bares her ass briefly\n",
            "True: Negative, Predicted: Negative (confidence: 0.97)\n",
            "\n",
            "Text: this was a great movie. something not only for black history month but as a reminder of the goodness of people and the statement that it truly does take a village to raise a child. the performances by s eptath was outstanding. mos def and his singing was off the hook. had to do a double take when i saw that was rosie perez there. but the supporting cast of actors and actresses made this worth watching. all the different stories they had was amazing. and how nanny protected jr and literally everyone else that was in her presence. i can truly understand her being the matriarch of that time period and even more so how tired she was in helping everyone. cant wait for it to come out on dvd. it would be a welcome addition to any movie library.\n",
            "True: Positive, Predicted: Positive (confidence: 0.98)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}